{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-processamento #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base e encoder manual ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    '../data/heart/processed/heart.csv',\n",
    "    sep = ';', encoding = 'utf-8'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encod_manual = pd.DataFrame.copy(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encod_manual['Sex'].replace({\n",
    "    'M': 0,\n",
    "    'F': 1\n",
    "}, inplace = True)\n",
    "\n",
    "df_encod_manual['ChestPainType'].replace({\n",
    "    'TA': 0,\n",
    "    'ATA': 1,\n",
    "    'NAP': 2,\n",
    "    'ASY': 3\n",
    "}, inplace = True)\n",
    "\n",
    "df_encod_manual['RestingECG'].replace({\n",
    "    'Normal': 0,\n",
    "    'ST': 1,\n",
    "    'LVH': 2\n",
    "}, inplace = True)\n",
    "\n",
    "df_encod_manual['ExerciseAngina'].replace({\n",
    "    'N': 0,\n",
    "    'Y': 1\n",
    "}, inplace = True)\n",
    "\n",
    "df_encod_manual['ST_Slope'].replace({\n",
    "    'Up': 0,\n",
    "    'Flat': 1,\n",
    "    'Down': 2\n",
    "}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separação da base em previsores e classe alvo ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores = df_encod_manual.iloc[:, 0:11].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "alvo = df_encod_manual.iloc[:, 11].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escalonamento ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores_esc = StandardScaler().fit_transform(previsores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores_df = pd.DataFrame(previsores_esc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LabelEncoder ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores_label = df.iloc[:, 0:11].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores_label[:, 1] = LabelEncoder().fit_transform(previsores[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores_label[:, 2] = LabelEncoder().fit_transform(previsores_label[:, 2])\n",
    "previsores_label[:, 6] = LabelEncoder().fit_transform(previsores_label[:, 6])\n",
    "previsores_label[:, 8] = LabelEncoder().fit_transform(previsores_label[:, 8])\n",
    "previsores_label[:, 10] = LabelEncoder().fit_transform(previsores_label[:, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OneHotEncoder ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores_hot = ColumnTransformer(\n",
    "    transformers = [('OneHot', OneHotEncoder(), [1, 2, 6, 8, 10])],\n",
    "    remainder = 'passthrough'\n",
    ").fit_transform(previsores_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores_hot_df = pd.DataFrame(previsores_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OneHot + Escalonamento ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoresHot_esc = StandardScaler().fit_transform(previsores_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoresHot_esc_df = pd.DataFrame(previsoresHot_esc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separação dos dados em treino e teste ##\n",
    "<span style=\"font-size: small;\"> \n",
    "- <strong>arrays:</strong> nomes dos atributos previsores e alvo.</br>\n",
    "- <strong>test_size:</strong> tamanho em porcentagem dos dados de teste. default é none. </br> \n",
    "- <strong>train_size:</strong> tamanho em porcentagem dos dados de treinamento.default é none. </br>  \n",
    "- <strong>random_state:</strong> nomeação de um estado aleatório. </br>\n",
    "- <strong>shuffle:</strong> embaralhamento dos dados aleatórios. Associado com o random_state ocorre o mesmo embaralhamento sempre. Default é True. </br>\n",
    "- <strong>stratify:</strong> Possibilidade de dividir os dados de forma estratificada. Default é None (nesse caso é mantido a proporção, isto é, se tem 30% de zeros e 70% de 1 no dataframe, na separação em treinamento e teste se manterá essa proporção). </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    previsoresHot_esc, alvo,\n",
    "    test_size = 0.3, random_state = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previsores #\n",
    "<span style=\"font-size: 13px;\">\n",
    "<li> <strong>previsores</strong> -> Atributos codificados manualmente sem escalonamento.</li></br>\n",
    "<li> <strong>previsoresHot_esc</strong> -> Atributos codificados com LabelEncoder e OneHotEncoder e escalonados.</li></br>\n",
    "<li> <strong>previsores_esc</strong> -> Atributos codificados manualmente e escalonados.</li></br>\n",
    "<li> <strong>previsores_hot</strong> -> Atributos codificados com OneHotEncoder sem escalonamento.</li></br>\n",
    "<li> <strong>previsores_label</strong> -> Atributos codificados com LabelEncoder e sem escalonamento. </li></br>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árvores de Decisão #\n",
    "\n",
    "<span style=\"font-size: 12.5px;\">\n",
    "\n",
    "**Introdução às Árvores de Decisão**\n",
    "\n",
    "As árvores de decisão são modelos de aprendizado de máquina que representam uma sequência de decisões em forma de uma estrutura de árvore. Elas são usadas para tarefas de classificação e regressão, onde o objetivo é prever a classe de uma observação (classificação) ou o valor de uma variável de destino (regressão) com base em várias características ou atributos.\n",
    "\n",
    "Funcionamento Básico\n",
    "\n",
    "O funcionamento das árvores de decisão pode ser resumido em alguns passos principais:\n",
    "\n",
    "1. **Divisão dos Dados**: A árvore começa com todos os dados no nó raiz e seleciona a melhor característica para dividir os dados em subconjuntos mais homogêneos.\n",
    "\n",
    "2. **Escolha da Melhor Divisão**: A melhor característica para divisão é escolhida com base em critérios como o índice Gini (para classificação) ou a redução da variância (para regressão).\n",
    "\n",
    "3. **Construção da Árvore**: A árvore é construída recursivamente, dividindo os dados em subconjuntos menores até que uma condição de parada seja alcançada.\n",
    "\n",
    "4. **Poda (Pruning)**: Após a construção da árvore, é comum podar partes da árvore que não contribuem significativamente para a sua capacidade de generalização.\n",
    "\n",
    "**Conceitos Importantes**\n",
    "\n",
    "Alguns conceitos importantes relacionados às árvores de decisão incluem:\n",
    "\n",
    "- **Nós (Nodes)**: Representam pontos de divisão na árvore, onde uma decisão é tomada com base em uma característica.\n",
    "- **Ramos (Branches)**: Representam os caminhos que seguem a partir de um nó para os nós filhos.\n",
    "- **Folhas (Leaves)**: Representam as saídas finais da árvore, onde uma decisão é tomada.\n",
    "\n",
    "</span>\n",
    "</br>\n",
    "<span style=\"font-size: 12.5px;\">\n",
    "\n",
    "\n",
    "**Índice Gini (para classificação):**\n",
    "\n",
    "$ \n",
    "Gini(D) = 1 - \\sum_{i=1}^{k} (p_i)^2 \n",
    "$\n",
    "\n",
    "onde $D$ é o conjunto de dados e $k$ é o número de classes. $p_i$ é a proporção de amostras da classe $i$ em $D$.\n",
    "\n",
    "\n",
    "**Entropia (para classificação):**\n",
    "\n",
    "A entropia é uma medida de impureza de um conjunto de dados. Quanto maior a entropia, maior a incerteza sobre a classe das amostras no conjunto de dados. A fórmula para calcular a entropia é dada por:\n",
    "\n",
    "$\n",
    "\\text{Entropia}(D) = - \\sum_{i=1}^{k} p_i \\log_2(p_i)\n",
    "$\n",
    "\n",
    "onde $D$ é o conjunto de dados, $k$ é o número de classes, e $p_i$ é a proporção de amostras da classe $i$ em $D$.\n",
    "\n",
    "**Ganho de Informação:**\n",
    "\n",
    "O ganho de informação é uma medida da quantidade de redução da entropia que resulta da divisão de um conjunto de dados com base em uma determinada característica. É usado para selecionar a melhor característica para divisão em árvores de decisão. O ganho de informação é calculado como a diferença entre a entropia do conjunto de dados original e a entropia ponderada dos subconjuntos resultantes da divisão.\n",
    "\n",
    "$\n",
    "\\text{Gain}(D, \\text{feature}) = \\text{Entropia}(D) - \\sum_{j} \\frac{|D_j|}{|D|} \\text{Entropia}(D_j)\n",
    "$\n",
    "\n",
    "onde $D$ é o conjunto de dados original, $D_j$ é o subconjunto resultante da divisão, e $\\text{feature}$ é a característica usada para divisão.\n",
    "\n",
    "**Comparação com o Índice Gini:**\n",
    "\n",
    "Tanto o índice Gini quanto a entropia são critérios comuns para medir a qualidade da divisão em árvores de decisão. Enquanto o índice Gini é calculado com base nas frequências das classes, a entropia é calculada com base na proporção das classes. Ambos os critérios são amplamente utilizados e geralmente produzem resultados semelhantes.\n",
    "\n",
    "\n",
    "**Parâmetros Importantes**\n",
    "\n",
    "Alguns parâmetros importantes em árvores de decisão incluem:\n",
    "\n",
    "- **Critério**: Define a função para medir a qualidade da divisão (por exemplo, \"gini\" ou \"entropy\" para classificação, \"mse\" para regressão).\n",
    "- **Profundidade Máxima**: Limita a profundidade da árvore para evitar overfitting.\n",
    "- **Número Mínimo de Amostras em Folha**: Define o número mínimo de amostras necessário em uma folha.\n",
    "- **Número Mínimo de Amostras para Divisão**: Define o número mínimo de amostras necessário para realizar uma divisão em um nó.\n",
    "\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "arvore = DecisionTreeClassifier(\n",
    "    criterion = 'gini',\n",
    "    random_state = 5,\n",
    "    max_depth = 4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "arvore.fit(x_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previsoes ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dados de Teste**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes_test = arvore.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dados de Treino**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes_train = arvore.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métricas ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dados de Teste**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 81.16%\n"
     ]
    }
   ],
   "source": [
    "acuracia_test = accuracy_score(y_test, previsoes_test) * 100.0\n",
    "print(\"Acurácia: %.2f%%\" % (acuracia_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusão: \n",
      " [[ 91  30]\n",
      " [ 22 133]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Matriz de Confusão: \\n\", confusion_matrix(y_test, previsoes_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatório: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.75      0.78       121\n",
      "           1       0.82      0.86      0.84       155\n",
      "\n",
      "    accuracy                           0.81       276\n",
      "   macro avg       0.81      0.81      0.81       276\n",
      "weighted avg       0.81      0.81      0.81       276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Relatório: \\n\", classification_report(y_test, previsoes_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dados de Treino**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 88.14%\n"
     ]
    }
   ],
   "source": [
    "acuracia_train = accuracy_score(y_train, previsoes_train) * 100.0\n",
    "print(\"Acurácia: %.2f%%\" % (acuracia_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusão: \n",
      " [[239  50]\n",
      " [ 26 326]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Matriz de Confusão: \\n\", confusion_matrix(y_train, previsoes_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatório: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.83      0.86       289\n",
      "           1       0.87      0.93      0.90       352\n",
      "\n",
      "    accuracy                           0.88       641\n",
      "   macro avg       0.88      0.88      0.88       641\n",
      "weighted avg       0.88      0.88      0.88       641\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Relatório: \\n\", classification_report(y_train, previsoes_train))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
