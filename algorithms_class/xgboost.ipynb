{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-processamento #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base e encoder manual ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    '../data/heart/processed/heart.csv',\n",
    "    sep = ';', encoding = 'utf-8'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encod_manual = pd.DataFrame.copy(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encod_manual['Sex'].replace({\n",
    "    'M': 0,\n",
    "    'F': 1\n",
    "}, inplace = True)\n",
    "\n",
    "df_encod_manual['ChestPainType'].replace({\n",
    "    'TA': 0,\n",
    "    'ATA': 1,\n",
    "    'NAP': 2,\n",
    "    'ASY': 3\n",
    "}, inplace = True)\n",
    "\n",
    "df_encod_manual['RestingECG'].replace({\n",
    "    'Normal': 0,\n",
    "    'ST': 1,\n",
    "    'LVH': 2\n",
    "}, inplace = True)\n",
    "\n",
    "df_encod_manual['ExerciseAngina'].replace({\n",
    "    'N': 0,\n",
    "    'Y': 1\n",
    "}, inplace = True)\n",
    "\n",
    "df_encod_manual['ST_Slope'].replace({\n",
    "    'Up': 0,\n",
    "    'Flat': 1,\n",
    "    'Down': 2\n",
    "}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separação da base em previsores e classe alvo ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores = df_encod_manual.iloc[:, 0:11].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "alvo = df_encod_manual.iloc[:, 11].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escalonamento ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores_esc = StandardScaler().fit_transform(previsores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores_df = pd.DataFrame(previsores_esc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LabelEncoder ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores_label = df.iloc[:, 0:11].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores_label[:, 1] = LabelEncoder().fit_transform(previsores[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores_label[:, 2] = LabelEncoder().fit_transform(previsores_label[:, 2])\n",
    "previsores_label[:, 6] = LabelEncoder().fit_transform(previsores_label[:, 6])\n",
    "previsores_label[:, 8] = LabelEncoder().fit_transform(previsores_label[:, 8])\n",
    "previsores_label[:, 10] = LabelEncoder().fit_transform(previsores_label[:, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OneHotEncoder ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores_hot = ColumnTransformer(\n",
    "    transformers = [('OneHot', OneHotEncoder(), [1, 2, 6, 8, 10])],\n",
    "    remainder = 'passthrough'\n",
    ").fit_transform(previsores_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores_hot_df = pd.DataFrame(previsores_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OneHot + Escalonamento ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoresHot_esc = StandardScaler().fit_transform(previsores_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoresHot_esc_df = pd.DataFrame(previsoresHot_esc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separação dos dados em treino e teste ##\n",
    "<span style=\"font-size: small;\"> \n",
    "- <strong>arrays:</strong> nomes dos atributos previsores e alvo.</br>\n",
    "- <strong>test_size:</strong> tamanho em porcentagem dos dados de teste. default é none. </br> \n",
    "- <strong>train_size:</strong> tamanho em porcentagem dos dados de treinamento.default é none. </br>  \n",
    "- <strong>random_state:</strong> nomeação de um estado aleatório. </br>\n",
    "- <strong>shuffle:</strong> embaralhamento dos dados aleatórios. Associado com o random_state ocorre o mesmo embaralhamento sempre. Default é True. </br>\n",
    "- <strong>stratify:</strong> Possibilidade de dividir os dados de forma estratificada. Default é None (nesse caso é mantido a proporção, isto é, se tem 30% de zeros e 70% de 1 no dataframe, na separação em treinamento e teste se manterá essa proporção). </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    previsoresHot_esc, alvo,\n",
    "    test_size = 0.3, random_state = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previsores #\n",
    "<span style=\"font-size: 13px;\">\n",
    "<li> <strong>previsores</strong> -> Atributos codificados manualmente sem escalonamento.</li></br>\n",
    "<li> <strong>previsoresHot_esc</strong> -> Atributos codificados com LabelEncoder e OneHotEncoder e escalonados.</li></br>\n",
    "<li> <strong>previsores_esc</strong> -> Atributos codificados manualmente e escalonados.</li></br>\n",
    "<li> <strong>previsores_hot</strong> -> Atributos codificados com OneHotEncoder sem escalonamento.</li></br>\n",
    "<li> <strong>previsores_label</strong> -> Atributos codificados com LabelEncoder e sem escalonamento. </li></br>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost #\n",
    "\n",
    "<span style=\"font-size: 13px;\">\n",
    "\n",
    "**Introdução** </br>\n",
    "XGBoost é uma biblioteca otimizada de aprendizado de máquina projetada para implementar o algoritmo de Gradient Boosting. Ele é conhecido por sua eficiência e velocidade em competições de ciência de dados e é amplamente utilizado em várias aplicações de aprendizado de máquina.\n",
    "\n",
    "**Gradient Boosting** </br>\n",
    "O Gradient Boosting é uma técnica de aprendizado de máquina que constrói um modelo preditivo por meio da combinação de vários modelos mais simples, geralmente árvores de decisão fracas. Ele trabalha de forma iterativa, treinando cada modelo para corrigir os erros dos modelos anteriores.\n",
    "\n",
    "**Árvores de Decisão** </br>\n",
    "As árvores de decisão são modelos de aprendizado de máquina que dividem os dados em subconjuntos menores com base em regras de decisão simples aprendidas a partir dos dados de treinamento.\n",
    "\n",
    "**Gradiente Descendente** </br>\n",
    "O Gradiente Descendente é um algoritmo de otimização usado para minimizar a função de perda ajustando iterativamente os parâmetros do modelo na direção oposta do gradiente da função de custo.\n",
    "\n",
    "**Formulação do XGBoost** </br>\n",
    "XGBoost combina as técnicas de Gradient Boosting com algumas melhorias para aumentar a velocidade e o desempenho. A fórmula do XGBoost para calcular a pontuação predita de um exemplo pode ser expressa como: </br>\n",
    "\n",
    "$ [ hat{y}_i = \\sum_{k=1}^{K} f_k(x_i) ] $\n",
    "\n",
    "Onde:\n",
    "- $ (hat{y}_i) $ é a pontuação predita para o exemplo $(i)$,\n",
    "- $ (K) $ é o número de árvores de decisão,\n",
    "- $ (f_k(x_i)) $ é a predição da $(k)$-ésima árvore para o exemplo $(i)$.\n",
    "\n",
    "**Parâmetros Importantes** </br>\n",
    "XGBoost possui diversos parâmetros que podem ser ajustados para otimizar o desempenho do modelo. Alguns dos parâmetros mais importantes incluem:\n",
    "\n",
    "- `learning_rate`: Taxa de aprendizado que controla a contribuição de cada árvore para a correção dos erros.\n",
    "- `max_depth`: Profundidade máxima de cada árvore.\n",
    "- `n_estimators`: Número de árvores de decisão a serem utilizadas.\n",
    "- `gamma`: Parâmetro de regularização que controla a complexidade do modelo.\n",
    "- `subsample`: Fração dos exemplos a serem amostrados aleatoriamente para treinar cada árvore.\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg = XGBClassifier(\n",
    "    max_depth = 2, learning_rate = 0.06,\n",
    "    n_estimators = 250, objective = 'binary:logistic',\n",
    "    booster = 'gbtree',\n",
    "    random_state = 5\n",
    ")\n",
    "xg.fit(x_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Previsões dados de teste**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes_test = xg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes_train = xg.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 86.59%\n"
     ]
    }
   ],
   "source": [
    "accuracy_test = accuracy_score(y_test, previsoes_test) * 100.0\n",
    "print(\"Acurácia: %.2f%%\" % accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[102  19]\n",
      " [ 18 137]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, previsoes_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.85       121\n",
      "           1       0.88      0.88      0.88       155\n",
      "\n",
      "    accuracy                           0.87       276\n",
      "   macro avg       0.86      0.86      0.86       276\n",
      "weighted avg       0.87      0.87      0.87       276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, previsoes_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Previsões dados de treino**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 91.73%\n"
     ]
    }
   ],
   "source": [
    "accuracy_train = accuracy_score(y_train, previsoes_train) * 100.0\n",
    "print(\"Acurácia: %.2f%%\" % accuracy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[254  35]\n",
      " [ 18 334]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, previsoes_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.91       289\n",
      "           1       0.91      0.95      0.93       352\n",
      "\n",
      "    accuracy                           0.92       641\n",
      "   macro avg       0.92      0.91      0.92       641\n",
      "weighted avg       0.92      0.92      0.92       641\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, previsoes_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits = 30, shuffle = True, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = XGBClassifier(\n",
    "    max_depth = 2, learning_rate = 0.06,\n",
    "    n_estimators = 250, objective = 'binary:logistic',\n",
    "    booster = 'gbtree',\n",
    "    random_state = 5\n",
    ")\n",
    "resultado = cross_val_score(\n",
    "    modelo, previsores, alvo, cv = kfold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média: 87.34%\n"
     ]
    }
   ],
   "source": [
    "print(\"Acurácia média: %.2f%%\" % (resultado.mean() * 100.0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
